name: Daily Scraper Chennai Again

on:
  schedule:
    - cron: "30 3 * * *"   # 9:00 AM IST
    - cron: "0 4 * * *"    # 9:30 AM IST
    - cron: "30 4 * * *"   # 10:00 AM IST
    - cron: "0 5 * * *"    # 10:30 AM IST
    - cron: "30 5 * * *"   # 11:00 AM IST
    - cron: "0 6 * * *"    # 11:30 AM IST
    - cron: "30 6 * * *"   # 12:00 PM IST
    - cron: "0 7 * * *"    # 12:30 PM IST
    - cron: "30 7 * * *"   # 1:00 PM IST
  workflow_dispatch:

jobs:
  run-script:
    runs-on: ubuntu-latest

    steps:

    # ✅ Step 1: Setup SSH
    - name: Setup SSH
      run: |
        mkdir -p ~/.ssh
        echo "${{ secrets.PRIVATE_KEY }}" > ~/.ssh/id_ed25519
        chmod 600 ~/.ssh/id_ed25519
        eval "$(ssh-agent -s)"
        ssh-add ~/.ssh/id_ed25519
        ssh-keyscan github.com >> ~/.ssh/known_hosts

    # ✅ Step 2: Clone private repo
    - name: Clone private repo
      run: |
        git clone git@github.com:LongwayDataTeam/Scrap_Again_Chennai.git

    # ✅ Step 3: Set up Python
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"
        cache: "pip"

    # ✅ Step 4: Install ONLY Google Chrome (NO chromedriver)
    - name: Install Google Chrome
      run: |
        sudo apt-get update
        sudo apt-get install -y wget unzip xvfb libnss3 libxss1 libxi6 fonts-liberation libu2f-udev

        wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo dpkg -i google-chrome-stable_current_amd64.deb || sudo apt-get -f install -y

        echo "✅ Installed Chrome Version:"
        google-chrome --version

    # ✅ Step 5: Remove any preinstalled chromedriver (Important!)
    - name: Remove system ChromeDriver
      run: |
        sudo rm -f /usr/local/bin/chromedriver
        sudo rm -f /usr/bin/chromedriver
        echo "✅ Old ChromeDriver removed"

    # ✅ Step 6: Install Python dependencies + webdriver-manager
    - name: Install Python dependencies
      run: |
        cd Scrap_Again_Chennai
        pip install --upgrade pip
        pip install -r requirements.txt

        # ✅ Required to auto-download matching driver
        pip install webdriver-manager

    # ✅ Step 7: Run scraper
    - name: Run scraping script
      env:
        GSHEET_CREDENTIALS: ${{ secrets.GSHEET_CREDENTIALS }}
      run: |
        cd Scrap_Again_Chennai
        python scrap_again_chennai.py
